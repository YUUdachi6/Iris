{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "ECE 4424 PROJECT Spring 2024\n",
        "IRIS\n",
        "By Chenglong Liao."
      ],
      "metadata": {
        "id": "N43PRuPHNGa4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "v__wxf6YMLuI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use sklearn repo to get iris dataset. This set has 3 kind iris, 50 for each, total 150."
      ],
      "metadata": {
        "id": "I3a7GCF_yBRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# loading data\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n"
      ],
      "metadata": {
        "id": "j7UHrhIPW1hM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris_df = pd.DataFrame(data=np.c_[X, y], columns=iris.feature_names + ['target'])\n",
        "print(iris_df)"
      ],
      "metadata": {
        "id": "LsuxXtuAXdTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instead of manual, using PCA function in sklearn to dimensionality reduction the data from 4 to 2."
      ],
      "metadata": {
        "id": "589yutW7ySzN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components=2)  # reduce the dimention from 4 to 2\n",
        "X_reduced = pca.fit_transform(X)\n",
        "\n"
      ],
      "metadata": {
        "id": "m8mde3iwX5vE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the figure after reduce the dimention.\n",
        "plt.figure(figsize=(8, 6))\n",
        "colors = ['red', 'green', 'blue']\n",
        "labels = iris.target_names\n",
        "\n",
        "for color, i, target_name in zip(colors, [0, 1, 2], labels):\n",
        "    plt.scatter(X_reduced[y == i, 0], X_reduced[y == i, 1], color=color, label=target_name, edgecolors='k')\n",
        "\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.title('PCA of Iris Dataset')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4k0-pvDDy4p9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For 150 data, 7/10 of them used for trainning and 3/10 used for testing."
      ],
      "metadata": {
        "id": "kY_SsHfazGGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
        "\n",
        "# Standardization\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "RoqiXryMXeoF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(10, 10), max_iter=1, warm_start=True, random_state=1, learning_rate_init=0.01)\n",
        "\n",
        "# store the result for each epoch\n",
        "epochs = 50\n",
        "# according to the loss output later (use 100 for testing), it levelled of after epoch 42, so epochs set to 50.\n",
        "train_accuracy = []\n",
        "test_accuracy = []\n",
        "loss_values = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    mlp.fit(X_train_scaled, y_train)\n",
        "    train_pred = mlp.predict(X_train_scaled)\n",
        "    test_pred = mlp.predict(X_test_scaled)\n",
        "    train_acc = accuracy_score(y_train, train_pred)\n",
        "    test_acc = accuracy_score(y_test, test_pred)\n",
        "    train_accuracy.append(train_acc)\n",
        "    test_accuracy.append(test_acc)\n",
        "    loss_values.append(mlp.loss_)\n",
        "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {mlp.loss_:.4f} - Train Accuracy: {train_acc:.4f} - Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ppAEHDIVW14_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(loss_values, label='Loss')\n",
        "plt.title('Loss over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dx8le3meml0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_accuracy, label='Train Accuracy')\n",
        "plt.plot(test_accuracy, label='Test Accuracy')\n",
        "plt.title('Accuracy over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mp3z83buW2EM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}